{"cells":[{"metadata":{"id":"t2wLZexbW-3A"},"cell_type":"markdown","source":"# **Hybrid System for Lung Cancer Classification**\n\nCreated by : Harjinder Singh <br>\nEmail : hjbrar7@gmail.com\n\nHere i will create a Hybrid System using **Particle Swarm Optimisation** and **Logistic Regression**.\n\nWe will see how to use **PSO** to extract usefull features from dataset and then train our model on these features."},{"metadata":{"id":"mJyS2D3QXF9J"},"cell_type":"markdown","source":"### **Importing Useful Libraries**"},{"metadata":{"id":"gq4YeE9RVuL0","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\n\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\n\nfrom sklearn.exceptions import DataConversionWarning\nwarnings.filterwarnings(action='ignore', category=DataConversionWarning)","execution_count":0,"outputs":[]},{"metadata":{"id":"Qfr3dKs1XJ77"},"cell_type":"markdown","source":"### **Importing Dataset**\n\nDataset that we are using here is taken from **UCI Machine Learning Repository**. <br>\nLink to dataset is <a href=\"http://archive.ics.uci.edu/ml/datasets/Lung+Cancer\" > Lung Cancer Dataset </a> <br>\n\nThis dataset contain 32 examples and 56 attributes. <br>\nsome of its fields are missing So we need to Purify this dataset before using it in out ML model.\n\n---\n### ***Note :***\nThis dataset is not big enough to train good Machine Learning Model\n"},{"metadata":{"id":"XQqW1BygV6w1","trusted":false},"cell_type":"code","source":"data_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/lung-cancer/lung-cancer.data\"\ndata = pd.read_csv(data_url,header=None)\ndata.head()","execution_count":0,"outputs":[]},{"metadata":{"id":"rJU-a7oBXn04","trusted":false},"cell_type":"code","source":"data.describe()","execution_count":0,"outputs":[]},{"metadata":{"id":"aalhdnsUV-F8","trusted":false},"cell_type":"code","source":"data.info()","execution_count":0,"outputs":[]},{"metadata":{"id":"Ed7Ax_i0ajW6"},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"id":"DQ2yzbeOirz6","trusted":false},"cell_type":"code","source":"# Convert the column name\ndata.columns = [str(x) for x in range(len(data.columns))]","execution_count":0,"outputs":[]},{"metadata":{"id":"tWH9bFcrixDh"},"cell_type":"markdown","source":"We will find the Columns with missing data and then fill the missing values"},{"metadata":{"id":"AYSvGGLCXZo9","trusted":false},"cell_type":"code","source":"cols = [ c for c in data.columns if np.dtype(data[c]) == 'O']\nprint(\"Columns with missing values are : \",cols)\n\nprint(\"Missing data is given with '?' \")\ndata[cols].head()","execution_count":0,"outputs":[]},{"metadata":{"id":"97lTp3CTcrFz"},"cell_type":"markdown","source":"Now we will convert these values to **np.int64** and convert **?** to **-1** <br>\nThen we will fill these -1 (missing values) with **mean** of the columnn."},{"metadata":{"id":"ireYLyYtYEGh","trusted":false},"cell_type":"code","source":"def convertValues(x):\n    try : x = np.int64(x)\n    except : x = -1\n    return x\n\nfor c in cols:\n    data[c] = pd.Series([convertValues(x) for x in data[c]])\n\nprint(\"Convert '?' to -1\")\ndata[cols].head()","execution_count":0,"outputs":[]},{"metadata":{"id":"Kds33chBgu3r"},"cell_type":"markdown","source":"Now fill missing values"},{"metadata":{"id":"qA7uVzJIcA7Q","trusted":false},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(missing_values= -1,strategy = \"mean\")\ndata[cols] = imputer.fit_transform(data[cols])\ndata[cols].head()","execution_count":0,"outputs":[]},{"metadata":{"id":"9liO6MfdhiS8"},"cell_type":"markdown","source":"## **Visualising Data**\n\nFirst column is our target values"},{"metadata":{"id":"b1WybO9xhh0P","trusted":false},"cell_type":"code","source":"sns.countplot(x='0',data=data)","execution_count":0,"outputs":[]},{"metadata":{"id":"HSesxkkicOQ6","trusted":false},"cell_type":"code","source":"plt.subplots(figsize=(15,10))\nsns.heatmap(cmap=\"coolwarm\",data=data)","execution_count":0,"outputs":[]},{"metadata":{"id":"nPQMsI8qk4qH"},"cell_type":"markdown","source":"In above graph we can see a number of features are **Higly -vely corelated** while some are also **highly +vely corelated**. So now we need to extract only useful features that can esure us good Machine Learning Model"},{"metadata":{"id":"_HtRB5WmlRYb"},"cell_type":"markdown","source":"# **Extracting useful features using PSO**\n\nOut of all these features, may be not all will participate for <br>\ngood accuracy. So we may have to choose only those features whose <br>\ncontribution can give us useful information.\n\nSo we will use **Particle Swarm Optimization** - *(PSO)* to <br>\nextract usefull features from our dataset"},{"metadata":{"id":"ZchUlH5glXdD","trusted":false},"cell_type":"code","source":"# Installing Pyswarm Library\n\n!python -m pip install pyswarms;","execution_count":0,"outputs":[]},{"metadata":{"id":"N7Ds3Dn9lcQQ","trusted":false},"cell_type":"code","source":"# importing the libraries\nimport pyswarms as ps","execution_count":0,"outputs":[]},{"metadata":{"id":"iHv-j53Q3kHw"},"cell_type":"markdown","source":"### Spliting data in Train and Test set"},{"metadata":{"id":"stZlkVgFl29c","trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX,y = data.iloc[:,1:].values, data.iloc[:,0].values\n\nXtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3)\nprint(\"Xtrain shape ; {} \\nytrain shape : {}\".format(Xtrain.shape,ytrain.shape))","execution_count":0,"outputs":[]},{"metadata":{"id":"twfvoOyQmWhb"},"cell_type":"markdown","source":"### Use of PSO"},{"metadata":{"id":"fryVe6vamE9W","trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Logistic Regression Classifier\nclf = LogisticRegression(solver='saga')\n\ndef cal_per_particle(mask,alpha,no_of_features=56):\n    subset=None   \n    if np.count_nonzero(mask) == 0:\n        subset = Xtrain\n    else :\n        subset = Xtrain[:,mask==1]\n    clf.fit(subset,ytrain)\n    pred = (clf.predict(subset)==ytrain).mean()\n    tmp = (alpha * (1.0 - pred) + (1.0 - alpha)* (1 - (subset.shape[1]/no_of_features)))\n    return tmp\n\ndef calc(x,alpha=0.81):\n    number_of_particles = x.shape[0]\n    arr = [cal_per_particle(x[i],alpha) for i in range(number_of_particles)]\n    return np.array(arr)","execution_count":0,"outputs":[]},{"metadata":{"id":"gM1ivAbcmuOp","trusted":false},"cell_type":"code","source":"%%time\n\nop1 = ['c1','c2']\nops = {'w':0.9,'k':30,'p':2}\nfor o in op1:\n    ops[o] = np.random.random()\ndims = Xtrain.shape[1]\noptimizer = ps.discrete.BinaryPSO(n_particles=32, dimensions=dims, options=ops)\ncost, pos = optimizer.optimize(calc, iters=800)\nprint(\"Options are : {}\".format(ops))","execution_count":0,"outputs":[]},{"metadata":{"id":"pqJmkhdpmz6P","trusted":false},"cell_type":"code","source":"cols = data.columns[1:]\nprint(\"Selected features are : \")\nprint([c for c,p in zip(cols,pos) if p==1 ])\nprint(\"Excluded features are : \")\nprint([c for c,p in zip(cols,pos) if p==0 ])","execution_count":0,"outputs":[]},{"metadata":{"id":"i7Yr0Ludn0vg"},"cell_type":"markdown","source":"### **Visualising PSO Optimizer Cost History**"},{"metadata":{"id":"ekOjZy02ntmu","trusted":false},"cell_type":"code","source":"from pyswarms.utils.plotters import plot_cost_history\n\nplot_cost_history(optimizer.cost_history)","execution_count":0,"outputs":[]},{"metadata":{"id":"jofzjul4oUZ6"},"cell_type":"markdown","source":"## **Checking Model performance over Selected Features**"},{"metadata":{"id":"6ZjOwkUcoR7q","trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\n\nclf = LogisticRegression(solver='saga')\n# selected trainging features\ns_xtrain = Xtrain[:,pos==1]\nclf.fit(s_xtrain,ytrain)\n\n# selected testing features\ns_xtest = Xtest[:,pos==1]\n\npred = clf.predict(s_xtest)","execution_count":0,"outputs":[]},{"metadata":{"id":"_2GajkjWn7Q3","trusted":false},"cell_type":"code","source":"mat = confusion_matrix(ytest,pred)\nsns.heatmap(mat, cmap=\"coolwarm\",fmt='d',annot=True)","execution_count":0,"outputs":[]},{"metadata":{"id":"-B7W2MJwp8pW","trusted":false},"cell_type":"code","source":"from sklearn.metrics import accuracy_score as ac\n\nprint(\"Accuracy Score : \",ac(ytest,pred))","execution_count":0,"outputs":[]},{"metadata":{"id":"H4P0mdhDpRiC"},"cell_type":"markdown","source":"## **Hyper Parameter Tunning**\nAs we see that after extracting the features with the help of **PSO**<br>\nWe were able to achieve **0.6 accuracy score**.\n\nSo now we will try to Tune our model so that we can increase our accuracy with the selected features."},{"metadata":{"id":"uwSL1jKIpOzN","trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix","execution_count":0,"outputs":[]},{"metadata":{"id":"ZfHr9Oz_xtte"},"cell_type":"markdown","source":"Some parameters for Tunning. We will create different combinations of paramerters to check for best solution."},{"metadata":{"id":"LUUOrcClw21E","trusted":false},"cell_type":"code","source":"c_param = [0.001, 0.01, 0.1, 1, 10, 100]\np_param = ['l1','l2']\n\nparam_list = [(c,p) for c in c_param for p in p_param]\nprint(\"Combinations are : \",param_list)","execution_count":0,"outputs":[]},{"metadata":{"id":"uslyOz3xy7Za"},"cell_type":"markdown","source":"We will keep a track of **C**, **penality** and **accuracy** so that we can use hyper parameters in our final Model."},{"metadata":{"id":"THDabqTTw9RD","trusted":false},"cell_type":"code","source":"C=None\nP=None\nAccu=0.0","execution_count":0,"outputs":[]},{"metadata":{"id":"BR9DVAMXxDcW","trusted":false},"cell_type":"code","source":"i,j=0,0\nf, axes = plt.subplots(3, 4, figsize=(20, 15), sharex=True)\nsns.despine(left=True)\ns_xtrain = Xtrain[:,pos==1]\ns_xtest = Xtest[:,pos==1]\n\nfor c,p in param_list:\n    clf = LogisticRegression(solver='saga',penalty=p,C=c)\n    clf.fit(s_xtrain,ytrain)\n    pred = clf.predict(s_xtest)\n    acc_score = accuracy_score(ytest,pred)\n    if acc_score > Accu:\n        Accu = acc_score\n        C,P=c,p\n    cm = confusion_matrix(ytest,pred)\n    axes[i,j].set_title(\"{ 'c' : \"+str(c)+\" , 'penality' : \"+p+\" }\")\n    sns.heatmap(cm,cmap=\"coolwarm\",fmt='d',annot=True,ax=axes[i,j])\n    if j == 3: i = (i+1)%4\n    j = (j+1)%4\n\nplt.setp(axes, yticks=[])\nplt.tight_layout()","execution_count":0,"outputs":[]},{"metadata":{"id":"YFRGF5As17QE"},"cell_type":"markdown","source":"### Result after Hyper Parameter Tunning"},{"metadata":{"id":"T12F6tSqxeAU","trusted":false},"cell_type":"code","source":"print(\"Best Accuracy : \",Accu)\nprint(\"Penalty : \",P)\nprint(\"C : \",c)","execution_count":0,"outputs":[]},{"metadata":{"id":"IfgCpQuM94Dy"},"cell_type":"markdown","source":"As we can see that after Hyper Parameter Tunning the <br>\naccuracy score os **0.6** which is quite good as per dataset."},{"metadata":{"id":"UndPNfiK_gKP"},"cell_type":"markdown","source":"# **Finalizing the Hybrid Model**"},{"metadata":{"id":"FblH1rTn_feN","trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix , accuracy_score, classification_report\nfrom sklearn.model_selection import cross_val_predict, cross_val_score, KFold","execution_count":0,"outputs":[]},{"metadata":{"id":"6_4xu_2lH0l4","trusted":false},"cell_type":"code","source":"xtrain,xtest,ytrain,ytest = train_test_split(X[:,pos==1],y,test_size=0.3)\n\nmodel = LogisticRegression(penalty=P,C=C,solver='saga')\nmodel.fit(xtrain,ytrain)\n\npred = model.predict(xtest)\n\nprint(\"Accuracy Score : \",accuracy_score(ytest,pred))\nc_mat = confusion_matrix(ytest,pred)\nsns.heatmap(c_mat,cmap=\"coolwarm\",fmt='d',annot=True)","execution_count":0,"outputs":[]},{"metadata":{"id":"TTMspoVlL1oV","trusted":false},"cell_type":"code","source":"cr = classification_report(ytest,pred,output_dict=True)\nprint(cr)","execution_count":0,"outputs":[]},{"metadata":{"id":"XbWYXeSoMpbx","trusted":false},"cell_type":"code","source":"cr_df = pd.DataFrame(cr)\ncr_df = cr_df.transpose()","execution_count":0,"outputs":[]},{"metadata":{"id":"35fwWBSZNK8Z","trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(cr_df,annot=True,cmap=\"coolwarm\",ax=ax)","execution_count":0,"outputs":[]},{"metadata":{"id":"YEvsrd6WQwv7","trusted":false},"cell_type":"code","source":"cr_df","execution_count":0,"outputs":[]},{"metadata":{"id":"0lzAU6wcObB0"},"cell_type":"markdown","source":"# **Summary**\n\nDuring this project the main motive was to use Soft Computing to make Hybrid System.<br>\nSo i used **Particle Swarm Optimization - (PSO)** with **Logistic Regression** to create a <br>\nHybrid System which extract features using PSO and then apply logistic Regression<br>\non the data to classify different type of Lung Cancer.\n\n\nThe data we used in this Project is available opensource on UCI Machine Learning <br>\nRepository. At last i was able to create Hybrid model that i used on this dataset.\n\n### Main Concepts used in this are\n\n\n*   Preprocessing Dataset\n*   Visualizing Data\n*   Feature Extraction using PSO\n*   Check Model Perfomance over Selected Features\n*   Hyper Parameter Tunning\n*   Finalising Model with Logistic Regression\n*   Classification Report\n   \n\n---\n\n\n\n---\n\n\n\n"}],"metadata":{"colab":{"name":"Hybrid Systems.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":4}