{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hybrid Systems.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyPjGgCJ0qNiBtFA9V3BGKWt"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2wLZexbW-3A",
        "colab_type": "text"
      },
      "source": [
        "# **Hybrid System for Lung Cancer Classification**\n",
        "\n",
        "Created by : Harjinder Singh <br>\n",
        "Email : hjbrar7@gmail.com\n",
        "\n",
        "Here i will create a Hybrid System using **Particle Swarm Optimisation** and **Logistic Regression**.\n",
        "\n",
        "We will see how to use **PSO** to extract usefull features from dataset and then train our model on these features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJyS2D3QXF9J",
        "colab_type": "text"
      },
      "source": [
        "### **Importing Useful Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq4YeE9RVuL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfr3dKs1XJ77",
        "colab_type": "text"
      },
      "source": [
        "### **Importing Dataset**\n",
        "\n",
        "Dataset that we are using here is taken from **UCI Machine Learning Repository**. <br>\n",
        "Link to dataset is <a href=\"http://archive.ics.uci.edu/ml/datasets/Lung+Cancer\" > Lung Cancer Dataset </a> <br>\n",
        "\n",
        "This dataset contain 32 examples and 56 attributes. <br>\n",
        "some of its fields are missing So we need to Purify this dataset before using it in out ML model.\n",
        "\n",
        "---\n",
        "### ***Note :***\n",
        "This dataset is not big enough to train good Machine Learning Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQqW1BygV6w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/lung-cancer/lung-cancer.data\"\n",
        "data = pd.read_csv(data_url,header=None)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJU-a7oBXn04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aalhdnsUV-F8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed7Ax_i0ajW6",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ2yzbeOirz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the column name\n",
        "data.columns = [str(x) for x in range(len(data.columns))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWH9bFcrixDh",
        "colab_type": "text"
      },
      "source": [
        "We will find the Columns with missing data and then fill the missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYSvGGLCXZo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = [ c for c in data.columns if np.dtype(data[c]) == 'O']\n",
        "print(\"Columns with missing values are : \",cols)\n",
        "\n",
        "print(\"Missing data is given with '?' \")\n",
        "data[cols].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97lTp3CTcrFz",
        "colab_type": "text"
      },
      "source": [
        "Now we will convert these values to **np.int64** and convert **?** to **-1** <br>\n",
        "Then we will fill these -1 (missing values) with **mean** of the columnn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ireYLyYtYEGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convertValues(x):\n",
        "    try : x = np.int64(x)\n",
        "    except : x = -1\n",
        "    return x\n",
        "\n",
        "for c in cols:\n",
        "    data[c] = pd.Series([convertValues(x) for x in data[c]])\n",
        "\n",
        "print(\"Convert '?' to -1\")\n",
        "data[cols].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kds33chBgu3r",
        "colab_type": "text"
      },
      "source": [
        "Now fill missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA7uVzJIcA7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(missing_values= -1,strategy = \"mean\")\n",
        "data[cols] = imputer.fit_transform(data[cols])\n",
        "data[cols].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9liO6MfdhiS8",
        "colab_type": "text"
      },
      "source": [
        "## **Visualising Data**\n",
        "\n",
        "First column is our target values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1WybO9xhh0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot(x='0',data=data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSesxkkicOQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplots(figsize=(15,10))\n",
        "sns.heatmap(cmap=\"coolwarm\",data=data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPQMsI8qk4qH",
        "colab_type": "text"
      },
      "source": [
        "In above graph we can see a number of features are **Higly -vely corelated** while some are also **highly +vely corelated**. So now we need to extract only useful features that can esure us good Machine Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HtRB5WmlRYb",
        "colab_type": "text"
      },
      "source": [
        "# **Extracting useful features using PSO**\n",
        "\n",
        "Out of all these features, may be not all will participate for <br>\n",
        "good accuracy. So we may have to choose only those features whose <br>\n",
        "contribution can give us useful information.\n",
        "\n",
        "So we will use **Particle Swarm Optimization** - *(PSO)* to <br>\n",
        "extract usefull features from our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZchUlH5glXdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installing Pyswarm Library\n",
        "\n",
        "!python -m pip install pyswarms;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Ds3Dn9lcQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the libraries\n",
        "import pyswarms as ps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHv-j53Q3kHw",
        "colab_type": "text"
      },
      "source": [
        "### Spliting data in Train and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stZlkVgFl29c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X,y = data.iloc[:,1:].values, data.iloc[:,0].values\n",
        "\n",
        "Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3)\n",
        "print(\"Xtrain shape ; {} \\nytrain shape : {}\".format(Xtrain.shape,ytrain.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twfvoOyQmWhb",
        "colab_type": "text"
      },
      "source": [
        "### Use of PSO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fryVe6vamE9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Logistic Regression Classifier\n",
        "clf = LogisticRegression(solver='saga')\n",
        "\n",
        "def cal_per_particle(mask,alpha,no_of_features=56):\n",
        "    subset=None   \n",
        "    if np.count_nonzero(mask) == 0:\n",
        "        subset = Xtrain\n",
        "    else :\n",
        "        subset = Xtrain[:,mask==1]\n",
        "    clf.fit(subset,ytrain)\n",
        "    pred = (clf.predict(subset)==ytrain).mean()\n",
        "    tmp = (alpha * (1.0 - pred) + (1.0 - alpha)* (1 - (subset.shape[1]/no_of_features)))\n",
        "    return tmp\n",
        "\n",
        "def calc(x,alpha=0.81):\n",
        "    number_of_particles = x.shape[0]\n",
        "    arr = [cal_per_particle(x[i],alpha) for i in range(number_of_particles)]\n",
        "    return np.array(arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM1ivAbcmuOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "op1 = ['c1','c2']\n",
        "ops = {'w':0.9,'k':30,'p':2}\n",
        "for o in op1:\n",
        "    ops[o] = np.random.random()\n",
        "dims = Xtrain.shape[1]\n",
        "optimizer = ps.discrete.BinaryPSO(n_particles=32, dimensions=dims, options=ops)\n",
        "cost, pos = optimizer.optimize(calc, iters=1000)\n",
        "print(\"Options are : {}\".format(ops))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqJmkhdpmz6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = data.columns[1:]\n",
        "print(\"Selected features are : \")\n",
        "print([c for c,p in zip(cols,pos) if p==1 ])\n",
        "print(\"Excluded features are : \")\n",
        "print([c for c,p in zip(cols,pos) if p==0 ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7Yr0Ludn0vg",
        "colab_type": "text"
      },
      "source": [
        "### **Visualising PSO Optimizer Cost History**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekOjZy02ntmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyswarms.utils.plotters import plot_cost_history\n",
        "\n",
        "plot_cost_history(optimizer.cost_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofzjul4oUZ6",
        "colab_type": "text"
      },
      "source": [
        "## **Checking Model performance over Selected Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZjOwkUcoR7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "clf = LogisticRegression(solver='saga')\n",
        "# selected trainging features\n",
        "s_xtrain = Xtrain[:,pos==1]\n",
        "clf.fit(s_xtrain,ytrain)\n",
        "\n",
        "# selected testing features\n",
        "s_xtest = Xtest[:,pos==1]\n",
        "\n",
        "pred = clf.predict(s_xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2GajkjWn7Q3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mat = confusion_matrix(ytest,pred)\n",
        "sns.heatmap(mat, cmap=\"coolwarm\",fmt='d',annot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B7W2MJwp8pW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score as ac\n",
        "\n",
        "print(\"Accuracy Score : \",ac(ytest,pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4P0mdhDpRiC",
        "colab_type": "text"
      },
      "source": [
        "## **Hyper Parameter Tunning**\n",
        "As we see that after extracting the features with the help of **PSO**<br>\n",
        "We were able to achieve **0.6 accuracy score**.\n",
        "\n",
        "So now we will try to Tune our model so that we can increase our accuracy with the selected features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwSL1jKIpOzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfHr9Oz_xtte",
        "colab_type": "text"
      },
      "source": [
        "Some parameters for Tunning. We will create different combinations of paramerters to check for best solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUUOrcClw21E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c_param = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "p_param = ['l1','l2']\n",
        "\n",
        "param_list = [(c,p) for c in c_param for p in p_param]\n",
        "print(\"Combinations are : \",param_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uslyOz3xy7Za",
        "colab_type": "text"
      },
      "source": [
        "We will keep a track of **C**, **penality** and **accuracy** so that we can use hyper parameters in our final Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THDabqTTw9RD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C=None\n",
        "P=None\n",
        "Accu=0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR9DVAMXxDcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i,j=0,0\n",
        "f, axes = plt.subplots(3, 4, figsize=(20, 15), sharex=True)\n",
        "sns.despine(left=True)\n",
        "s_xtrain = Xtrain[:,pos==1]\n",
        "s_xtest = Xtest[:,pos==1]\n",
        "\n",
        "for c,p in param_list:\n",
        "    clf = LogisticRegression(solver='saga',penalty=p,C=c)\n",
        "    clf.fit(s_xtrain,ytrain)\n",
        "    pred = clf.predict(s_xtest)\n",
        "    acc_score = accuracy_score(ytest,pred)\n",
        "    if acc_score > Accu:\n",
        "        Accu = acc_score\n",
        "        C,P=c,p\n",
        "    cm = confusion_matrix(ytest,pred)\n",
        "    axes[i,j].set_title(\"{ 'c' : \"+str(c)+\" , 'penality' : \"+p+\" }\")\n",
        "    sns.heatmap(cm,cmap=\"coolwarm\",fmt='d',annot=True,ax=axes[i,j])\n",
        "    if j == 3: i = (i+1)%4\n",
        "    j = (j+1)%4\n",
        "\n",
        "plt.setp(axes, yticks=[])\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFRGF5As17QE",
        "colab_type": "text"
      },
      "source": [
        "### Result after Hyper Parameter Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T12F6tSqxeAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Best Accuracy : \",Accu)\n",
        "print(\"Penalty : \",P)\n",
        "print(\"C : \",c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfgCpQuM94Dy",
        "colab_type": "text"
      },
      "source": [
        "As we can see that after Hyper Parameter Tunning the <br>\n",
        "accuracy score os **0.6** which is quite good as per dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UndPNfiK_gKP",
        "colab_type": "text"
      },
      "source": [
        "# **Finalizing the Hybrid Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FblH1rTn_feN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix , accuracy_score, classification_report\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score, KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_4xu_2lH0l4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain,xtest,ytrain,ytest = train_test_split(X[:,pos==1],y,test_size=0.3)\n",
        "\n",
        "model = LogisticRegression(penalty=P,C=C,solver='saga')\n",
        "model.fit(xtrain,ytrain)\n",
        "\n",
        "pred = model.predict(xtest)\n",
        "\n",
        "print(\"Accuracy Score : \",accuracy_score(ytest,pred))\n",
        "c_mat = confusion_matrix(ytest,pred)\n",
        "sns.heatmap(c_mat,cmap=\"coolwarm\",fmt='d',annot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTMspoVlL1oV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cr = classification_report(ytest,pred,output_dict=True)\n",
        "print(cr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbWYXeSoMpbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cr_df = pd.DataFrame(cr)\n",
        "cr_df = cr_df.transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35fwWBSZNK8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(cr_df,annot=True,cmap=\"coolwarm\",ax=ax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEvsrd6WQwv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cr_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lzAU6wcObB0",
        "colab_type": "text"
      },
      "source": [
        "# **Summary**\n",
        "\n",
        "During this project the main motive was to use Soft Computing to make Hybrid System.<br>\n",
        "So i used **Particle Swarm Optimization - (PSO)** with **Logistic Regression** to create a <br>\n",
        "Hybrid System which extract features using PSO and then apply logistic Regression<br>\n",
        "on the data to classify different type of Lung Cancer.\n",
        "\n",
        "\n",
        "The data we used in this Project is available opensource on UCI Machine Learning <br>\n",
        "Repository. At last i was able to create Hybrid model that i used on this dataset.\n",
        "\n",
        "### Main Concepts used in this are\n",
        "\n",
        "\n",
        "*   Preprocessing Dataset\n",
        "*   Visualizing Data\n",
        "*   Feature Extraction using PSO\n",
        "*   Check Model Perfomance over Selected Features\n",
        "*   Hyper Parameter Tunning\n",
        "*   Finalising Model with Logistic Regression\n",
        "*   Classification Report\n",
        "   \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}